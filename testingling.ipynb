{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049529b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lipst', 'ipsti', 'pstic', 'stick', 'tspil', 'itspi', 'citsp', 'kcits']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordfreq import top_n_list\n",
    "\n",
    "english_words = set(top_n_list(\"en\", 100000))\n",
    "\n",
    "\n",
    "def letters_from_words(words):\n",
    "    \"\"\"Flatten list of words into a list of characters.\"\"\"\n",
    "    chars = []\n",
    "    for w in words:\n",
    "        chars.extend(list(w))\n",
    "    return chars\n",
    "\n",
    "# basic word wise selectors like first letters, last letters, etc\n",
    "\n",
    "\n",
    "def first_letters(words):\n",
    "    return \"\".join(w[0] for w in words if len(w) > 0)\n",
    "\n",
    "\n",
    "def last_letters(words):\n",
    "    return \"\".join(w[-1] for w in words if len(w) > 0)\n",
    "\n",
    "\n",
    "def middle_letters(words):\n",
    "    return \"\".join(w[len(w)//2] for w in words if len(w) >= 3)\n",
    "\n",
    "# nth letter selectors\n",
    "\n",
    "\n",
    "def nth_letters(chars, n):\n",
    "    return \"\".join(chars[0::n])\n",
    "\n",
    "\n",
    "def odd_letters(chars):\n",
    "    return \"\".join(chars[0::2])\n",
    "\n",
    "\n",
    "def even_letters(chars):\n",
    "    return \"\".join(chars[1::2])\n",
    "\n",
    "# half words\n",
    "\n",
    "\n",
    "def first_half(w):\n",
    "    return w[: len(w)//2]\n",
    "\n",
    "\n",
    "def second_half(w):\n",
    "    return w[len(w)//2:]\n",
    "\n",
    "# substrings\n",
    "\n",
    "\n",
    "def word_substrings(w):\n",
    "    subs = []\n",
    "    for i in range(len(w)):\n",
    "        for j in range(i+1, len(w)+1):\n",
    "            subs.append(w[i:j])\n",
    "    return subs\n",
    "\n",
    "\n",
    "def string_substrings(s):\n",
    "    subs = []\n",
    "    for i in range(len(s)):\n",
    "        for j in range(i+1, len(s)+1):\n",
    "            subs.append(s[i:j])\n",
    "    return subs\n",
    "\n",
    "# sometimes you have to take the halves of two words and frakenstein them\n",
    "\n",
    "\n",
    "def cross_half_combinations(words):\n",
    "    \"\"\"Combine first/second halves across all words correctly.\"\"\"\n",
    "    halves = []\n",
    "\n",
    "    halves_list = []\n",
    "    for w in words:\n",
    "        if len(w) >= 2:\n",
    "            halves_list.append((first_half(w), second_half(w)))\n",
    "\n",
    "    # combine every half-A with every half-B\n",
    "    for (A_fh, A_sh) in halves_list:\n",
    "        for (B_fh, B_sh) in halves_list:\n",
    "\n",
    "            halves.extend([\n",
    "                A_fh + B_fh,\n",
    "                A_fh + B_sh,\n",
    "                A_sh + B_fh,\n",
    "                A_sh + B_sh,\n",
    "            ])\n",
    "\n",
    "    return halves\n",
    "\n",
    "# combine them all!\n",
    "\n",
    "\n",
    "def generate_all_selectors(fodder, length=None):\n",
    "    \"\"\"\n",
    "    Generate ALL selector possibilities:\n",
    "    - word-wise (first/last/middle letters)\n",
    "    - string-wise (odd/even/every-nth)\n",
    "    - half-word (first half / second half)\n",
    "    - cross-half combinations\n",
    "    - all substrings of each word\n",
    "    - all substrings of the full string\n",
    "    \"\"\"\n",
    "\n",
    "    words = fodder.split()\n",
    "    chars = letters_from_words(words)\n",
    "    combined = \"\".join(chars)\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    # word-level selectors\n",
    "    candidates.append(first_letters(words))\n",
    "    candidates.append(last_letters(words))\n",
    "    candidates.append(middle_letters(words))\n",
    "\n",
    "    # string-level selectors\n",
    "    candidates.append(odd_letters(chars))\n",
    "    candidates.append(even_letters(chars))\n",
    "\n",
    "    for n in range(2, max(3, len(chars) + 1)):\n",
    "        candidates.append(nth_letters(chars, n))\n",
    "\n",
    "    # half-word selectors\n",
    "    for w in words:\n",
    "        if len(w) >= 2:\n",
    "            candidates.append(first_half(w))\n",
    "            candidates.append(second_half(w))\n",
    "\n",
    "    # cross-half combinations\n",
    "    candidates.extend(cross_half_combinations(words))\n",
    "\n",
    "    for w in words:\n",
    "        candidates.extend(word_substrings(w))\n",
    "    candidates.extend(string_substrings(combined))\n",
    "\n",
    "    # accomodate for the reverse case\n",
    "    rev_candidates = [c[::-1] for c in candidates]\n",
    "    candidates.extend(rev_candidates)\n",
    "\n",
    "    candidates = [c for c in candidates if c]\n",
    "\n",
    "    if length is not None:\n",
    "        candidates = [c for c in candidates if len(c) == length]\n",
    "\n",
    "    # remove duplicates\n",
    "    candidates = list(dict.fromkeys(candidates))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "generate_all_selectors(\"lipstick\", length=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36425789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from wordfreq import top_n_list\n",
    "\n",
    "english_words = set(top_n_list(\"en\", 100000))\n",
    "\n",
    "\n",
    "def clean_fodder(text):\n",
    "    \"\"\"\n",
    "    Clean the fodder by removing apostrophes, hyphens, dashes, punctuations,\n",
    "    forces lowercase, and collapse spaces to treat them like a continous string\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"[’'`]\", \"\", text)\n",
    "    text = re.sub(r\"[-–—]\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z ]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "\n",
    "def ngrams_of(n, word):\n",
    "    \"\"\"\n",
    "    Return all n-grams of the fodders\n",
    "    \"\"\"\n",
    "    word = clean_fodder(word)\n",
    "    word = word.replace(\" \", \"\")  # treat as continuous string\n",
    "    ngrams = set()\n",
    "\n",
    "    # normal hiddens\n",
    "    for i in range(len(word) - n + 1):\n",
    "        ngrams.add(word[i: i + n])\n",
    "\n",
    "    # the reverse case\n",
    "    rev = word[::-1]\n",
    "    for i in range(len(rev) - n + 1):\n",
    "        ngrams.add(rev[i:i+n])\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def filter_real_words(ngrams):\n",
    "    \"\"\"\n",
    "    input: n-grams\n",
    "    output: the n-grams that are valid english words\n",
    "    \"\"\"\n",
    "    real_words = set()\n",
    "\n",
    "    for ng in ngrams:\n",
    "        cleaned = ng.lower()\n",
    "\n",
    "        if cleaned in english_words:\n",
    "            real_words.add(cleaned)\n",
    "\n",
    "    return real_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224e8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_fodder(text):\n",
    "    \"\"\"\n",
    "    Clean the fodder by removing apostrophes, hyphens, dashes, punctuations,\n",
    "    forces lowercase, and collapse spaces to treat them like a continous string\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"[’'`]\", \"\", text)\n",
    "    text = re.sub(r\"[-–—]\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z ]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c11125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acting',\n",
       " 'artnoc',\n",
       " 'cartno',\n",
       " 'contra',\n",
       " 'ctingo',\n",
       " 'emnrev',\n",
       " 'ernmen',\n",
       " 'evogni',\n",
       " 'gnitca',\n",
       " 'govern',\n",
       " 'ingove',\n",
       " 'itcart',\n",
       " 'mnrevo',\n",
       " 'nemnre',\n",
       " 'ngover',\n",
       " 'nitcar',\n",
       " 'nrevog',\n",
       " 'ntract',\n",
       " 'ognitc',\n",
       " 'ontrac',\n",
       " 'overnm',\n",
       " 'ractin',\n",
       " 'revogn',\n",
       " 'rnment',\n",
       " 'tcartn',\n",
       " 'tingov',\n",
       " 'tnemnr',\n",
       " 'tracti',\n",
       " 'vernme',\n",
       " 'vognit'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_of(6, \"contract in government\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fa0392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acting', 'contra', 'govern'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_real_words(ngrams_of(6, \"contract in government\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
